{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning - Nvidia's \"End to End Learning for Self-Driving Cars\" Model\n",
    "\n",
    "This notebook implement the mode based on the description [here](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generators setup\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#height = 80\n",
    "#width = 160\n",
    "height = 160\n",
    "width = 320\n",
    "\n",
    "dataSubDir = 'data'\n",
    "dataLog = 'driving_log.csv'\n",
    "dataDir = os.path.join('data', dataSubDir)\n",
    "\n",
    "samples = []\n",
    "with open(os.path.join(dataDir,dataLog)) as csvfile:\n",
    "    samples = list(csv.reader(csvfile))\n",
    "\n",
    "\n",
    "#train_samples = samples\n",
    "#validation_samples = samples\n",
    "train_samples, validation_samples = train_test_split(samples[1:])\n",
    "    \n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        # shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = os.path.join(dataDir,batch_sample[0].strip())\n",
    "                center_img = cv2.imread(name)\n",
    "                center_image = center_img\n",
    "                #center_image = cv2.resize(center_img,(width,height))\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            #yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            yield X_train, y_train\n",
    "\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "print('generators setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, Lambda\n",
    "from keras.layers.convolutional import Cropping2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)),input_shape=(height, width, 3)))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1))\n",
    "model.add(Conv2D(24,5,5))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(36,5,5))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(48,5,5))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,3,3))\n",
    "model.add(Conv2D(64,3,3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mse' , metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run the following line when you want train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6027/6027 [==============================] - 15s - loss: 0.0125 - acc: 0.5399 - val_loss: 0.0101 - val_acc: 0.5510\n",
      "Epoch 2/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0104 - acc: 0.5399 - val_loss: 0.0105 - val_acc: 0.5510\n",
      "Epoch 3/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0100 - acc: 0.5399 - val_loss: 0.0107 - val_acc: 0.5510\n",
      "Epoch 4/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0096 - acc: 0.5399 - val_loss: 0.0111 - val_acc: 0.5510\n",
      "Epoch 5/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0092 - acc: 0.5399 - val_loss: 0.0100 - val_acc: 0.5510\n",
      "Epoch 6/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0090 - acc: 0.5399 - val_loss: 0.0103 - val_acc: 0.5510\n",
      "Epoch 7/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0085 - acc: 0.5399 - val_loss: 0.0121 - val_acc: 0.5510\n",
      "Epoch 8/10\n",
      "6027/6027 [==============================] - 14s - loss: 0.0079 - acc: 0.5399 - val_loss: 0.0138 - val_acc: 0.5510\n",
      "Epoch 9/10\n",
      "6027/6027 [==============================] - 13s - loss: 0.0073 - acc: 0.5399 - val_loss: 0.0125 - val_acc: 0.5510\n",
      "Epoch 10/10\n",
      "6027/6027 [==============================] - 14s - loss: 0.0063 - acc: 0.5399 - val_loss: 0.0123 - val_acc: 0.5510\n",
      "0.0101 0.0101 0.0101 0.0101\n",
      "0.0105 0.0105 0.0105 0.0105\n",
      "0.0107 0.0107 0.0107 0.0107\n",
      "0.0111 0.0111 0.0111 0.0111\n",
      "0.0100 0.0100 0.0100 0.0100\n",
      "0.0103 0.0103 0.0103 0.0103\n",
      "0.0121 0.0121 0.0121 0.0121\n",
      "0.0138 0.0138 0.0138 0.0138\n",
      "0.0125 0.0125 0.0125 0.0125\n",
      "0.0123 0.0123 0.0123 0.0123\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, \\\n",
    "                              samples_per_epoch = len(train_samples), \\\n",
    "                              validation_data=validation_generator, \\\n",
    "                              nb_val_samples=len(validation_samples), nb_epoch=10) #, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### switch cell to code cell in order to run code below\n",
    "\n",
    "loss = history.history['loss']\n",
    "acc = history.history['acc']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "for i in range(len(loss)):\n",
    "    print('{2:.4f} {2:.4f} {2:.4f} {2:.4f}'.format(loss[i], acc[i], val_loss[i], val_acc[i]))\n",
    "    \n",
    "predict = model.predict_generator(train_generator, val_samples=len(train_samples))\n",
    "\n",
    "gen = generator(samples)\n",
    "x, y = next(gen)\n",
    "for i in range(len(train_samples)):\n",
    "    print('{0:+.4f} {1:+.4f}'.format(y[i], predict[i][0]))\n",
    "\n",
    "model.save('my_model.h5')\n",
    "print('Saved model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IntroToTensorFlow]",
   "language": "python",
   "name": "conda-env-IntroToTensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
